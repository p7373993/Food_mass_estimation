version: '3.8'

services:
  ml-server:
    image: food-calorie-ml-server:latest
    env_file:
      - .env
    ports:
      - "8001:8001"
    environment:
      # 환경 변수 설정
      - DEBUG_MODE=false
      - ENABLE_MULTIMODAL=true
      - LLM_PROVIDER=gemini
      - LLM_MODEL_NAME=gemini-2.5-flash
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - PYTHONPATH=/app
      - PYTHONUNBUFFERED=1
    volumes:
      # 로그 및 결과 파일을 호스트와 공유
      - ./logs:/app/logs
      - ./results:/app/results
      - ./data:/app/data
      # 모델 파일을 호스트와 공유 (선택사항)
      - ./weights:/app/weights
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - food-calorie-network

  # 개발 환경용 서비스 (선택사항)
  ml-server-dev:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: food-calorie-ml-server-dev
    ports:
      - "8002:8001"
    environment:
      - DEBUG_MODE=true
      - ENABLE_MULTIMODAL=true
      - LLM_PROVIDER=gemini
      - LLM_MODEL_NAME=gemini-2.5-flash
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - PYTHONPATH=/app
      - PYTHONUNBUFFERED=1
    volumes:
      - ./logs:/app/logs
      - ./results:/app/results
      - ./data:/app/data
      - ./weights:/app/weights
      # 개발 시 코드 변경사항 반영
      - .:/app
    restart: unless-stopped
    profiles:
      - dev
    networks:
      - food-calorie-network

networks:
  food-calorie-network:
    driver: bridge 
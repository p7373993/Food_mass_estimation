import logging
import numpy as np
import google.generativeai as genai
from typing import Dict
import json
import re
import cv2
import base64

from config.settings import settings
from utils.base_model import BaseModel

class LLMMassEstimator(BaseModel):
    """
    LLM (Gemini)ì„ ì‚¬ìš©í•˜ì—¬ ì§ˆëŸ‰ì„ ì¶”ì •í•˜ëŠ” ë˜í¼ í´ë˜ìŠ¤. (ì¼ë°˜í™” ë° ìê¸° êµì • ë¡œì§ ê°•í™”)
    """
    
    def get_model_name(self) -> str:
        return "Gemini LLM ëª¨ë¸"
    
    def _initialize_model(self) -> None:
        if not settings.GEMINI_API_KEY:
            self._log_error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤", ValueError(".env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”"))
            self._model = None
            return
        
        try:
            genai.configure(api_key=settings.GEMINI_API_KEY)
            self._model = genai.GenerativeModel(settings.LLM_MODEL_NAME)
            self._log_success(f"ë¡œë”© ì„±ê³µ: {settings.LLM_MODEL_NAME}")
        except Exception as e:
            self._log_error("ì„¤ì • ì‹¤íŒ¨", e)
            self._model = None
    
    def estimate_mass_from_features(self, features: dict, debug_helper=None) -> dict:
        if self._model is None:
            return {"error": "LLM ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
        
        food_objects = features.get("food_objects", [])
        if not food_objects:
            return {"error": "ìŒì‹ ê°ì²´ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
        
        # ì—¬ëŸ¬ ìŒì‹ì— ëŒ€í•´ ê°ê° ì§ˆëŸ‰ ì¶”ì •
        food_estimations = []
        
        for i, food in enumerate(food_objects):
            prompt = self._build_prompt_for_food(features, food, i)
            try:
                response = self._model.generate_content(
                    prompt,
                    generation_config=genai.types.GenerationConfig(
                        temperature=settings.LLM_TEMPERATURE, top_p=settings.LLM_TOP_P
                    ),
                )
                mass_info = self._parse_response(response.text)
                if debug_helper:
                    debug_helper.log_initial_mass_calculation_debug(features, prompt, response.text, mass_info)
                
                # ìŒì‹ë³„ ì •ë³´ ì¶”ê°€
                mass_info["food_index"] = i
                mass_info["food_bbox"] = food.get("bbox", [])
                mass_info["food_pixel_area"] = food.get("pixel_area", 0)
                food_estimations.append(mass_info)
                    
            except Exception as e:
                logging.error(f"ìŒì‹ {i} ì§ˆëŸ‰ ì¶”ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                food_estimations.append({
                    "error": str(e),
                    "food_index": i,
                    "food_bbox": food.get("bbox", []),
                    "food_pixel_area": food.get("pixel_area", 0)
                })
        
        return {
            "food_estimations": food_estimations,
            "food_count": len(food_objects)
        }

    def verify_mass_with_multimodal(self, image: np.ndarray, initial_estimation: dict, features: dict) -> dict:
        if self._model is None:
            return {"error": "LLM ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
        try:
            multimodal_model = genai.GenerativeModel(settings.MULTIMODAL_MODEL_NAME or settings.LLM_MODEL_NAME)
            
            # ë””ë²„ê·¸: ì›ë³¸ ì´ë¯¸ì§€ ì •ë³´ ì¶œë ¥
            if settings.DEBUG_MODE:
                print(f"\nğŸ” ë©€í‹°ëª¨ë‹¬ ê²€ì¦ ì´ë¯¸ì§€ ì²˜ë¦¬:")
                print(f"   ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°: {image.shape}")
                print(f"   ì›ë³¸ BGR í‰ê· : {np.mean(image, axis=(0,1))}")
            
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            max_size = 1536
            h, w = image_rgb.shape[:2]
            
            if settings.DEBUG_MODE:
                print(f"   RGB ë³€í™˜ í›„ í¬ê¸°: {image_rgb.shape}")
                print(f"   RGB í‰ê· : {np.mean(image_rgb, axis=(0,1))}")
            
            if max(h, w) > max_size:
                scale = max_size / max(h, w)
                new_h, new_w = int(h * scale), int(w * scale)
                image_rgb = cv2.resize(image_rgb, (new_w, new_h))
                if settings.DEBUG_MODE:
                    print(f"   ë¦¬ì‚¬ì´ì¦ˆ í›„ í¬ê¸°: {image_rgb.shape} (ìŠ¤ì¼€ì¼: {scale:.3f})")
                    print(f"   ë¦¬ì‚¬ì´ì¦ˆ í›„ RGB í‰ê· : {np.mean(image_rgb, axis=(0,1))}")
            
            # ë””ë²„ê·¸: ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ì €ì¥
            if settings.DEBUG_MODE:
                cv2.imwrite("debug_multimodal_input.jpg", cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR))
                print(f"   ë©€í‹°ëª¨ë‹¬ ì…ë ¥ ì´ë¯¸ì§€ ì €ì¥: debug_multimodal_input.jpg")
            
            # ë°˜ë“œì‹œ BGRë¡œ ë³€í™˜ í›„ ì¸ì½”ë”© (ìƒ‰ìƒ ë¬¸ì œ ë°©ì§€)
            image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
            _, buffer = cv2.imencode('.jpg', image_bgr)
            image_base64 = base64.b64encode(buffer).decode('utf-8')
            
            if settings.DEBUG_MODE:
                print(f"   JPEG ë²„í¼ í¬ê¸°: {len(buffer)} bytes")
                print(f"   Base64 ê¸¸ì´: {len(image_base64)} ë¬¸ì")
            
            prompt = self._build_multimodal_prompt(initial_estimation, features)
            multimodal_content = [{"parts": [{"text": prompt}, {"inline_data": {"mime_type": "image/jpeg", "data": image_base64}}]}]
            
            if settings.DEBUG_MODE:
                print(f"   ë©€í‹°ëª¨ë‹¬ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} ë¬¸ì")
            
            response = multimodal_model.generate_content(
                multimodal_content,
                generation_config=genai.types.GenerationConfig(
                    temperature=settings.LLM_TEMPERATURE, top_p=settings.LLM_TOP_P
                ),
            )
            
            if settings.DEBUG_MODE:
                print(f"   LLM ì‘ë‹µ ê¸¸ì´: {len(response.text)} ë¬¸ì")
                print(f"   LLM ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {response.text[:200]}...")
            
            return self._parse_multimodal_response(response.text, initial_estimation)
        except Exception as e:
            logging.error(f"ë©€í‹°ëª¨ë‹¬ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {"error": str(e)}

    def _build_prompt_for_food(self, features: dict, food: dict, food_index: int) -> str:
        """íŠ¹ì • ìŒì‹ ê°ì²´ì— ëŒ€í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        reference_objects = features.get("reference_objects", [])
        depth_scale_info = features.get("depth_scale_info", {})
        has_reference = len(reference_objects) > 0
        has_depth_scale = depth_scale_info.get('has_scale', False)
        
        prompt = f"ìŒì‹ {food_index + 1} ì§ˆëŸ‰ ì¶”ì • ë¶„ì„:\n\n"
        prompt += f"ğŸ½ï¸ ìŒì‹ ì •ë³´:\n  - ì¢…ë¥˜: {food.get('class_name', 'ì•Œìˆ˜ì—†ìŒ')}\n  - í”½ì…€ ë©´ì : {food.get('pixel_area', 0):,}í”½ì…€\n"
        food_depth = food.get('depth_info', {})
        prompt += f"  - í‰ê·  ê¹Šì´ê°’(ìƒëŒ€ì ): {food_depth.get('mean_depth', 0.0):.3f}\n  - ê¹Šì´ ë³€í™”ëŸ‰(ìƒëŒ€ì ): {food_depth.get('depth_variation', 0.0):.3f}\n"
        
        if has_reference:
            ref_obj = reference_objects[0]
            prompt += f"\nğŸ“ ê¸°ì¤€ ë¬¼ì²´ ì •ë³´:\n  - ì¢…ë¥˜: {ref_obj.get('class_name')}\n"
            real_size = ref_obj.get('real_size', {})
            if real_size:
                prompt += f"  - ì‹¤ì œ í¬ê¸°: {real_size.get('width', 0):.1f}cm Ã— {real_size.get('height', 0):.1f}cm, ë‘ê»˜: {real_size.get('thickness', 0):.1f}cm\n"
        
        if has_depth_scale:
            prompt += f"\nğŸ” ê³„ì‚°ëœ ì‹¤ì œ ìŠ¤ì¼€ì¼:\n  - ê¹Šì´ ìŠ¤ì¼€ì¼: {depth_scale_info.get('depth_scale_cm_per_unit', 0.0):.4f} cm/unit\n"
            if depth_scale_info.get('pixel_per_cm2_ratio'):
                prompt += f"  - ë©´ì  ë¹„ìœ¨: {depth_scale_info.get('pixel_per_cm2_ratio'):.2f} pixels/cmÂ²\n"
        
        prompt += "\nğŸ¯ ê³„ì‚° ê³¼ì œ:\nìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ ìŒì‹ì˜ ì§ˆëŸ‰ì„ g(ê·¸ë¨) ë‹¨ìœ„ë¡œ ì¶”ì •í•˜ì„¸ìš”. ë¶€í”¼(cmÂ³)ë¥¼ ë¨¼ì € ê³„ì‚°í•œ í›„, ì¼ë°˜ì ì¸ ìŒì‹ ë°€ë„(ì•½ 0.8~1.2 g/cmÂ³)ë¥¼ ì ìš©í•˜ì„¸ìš”.\n"
        prompt += "\nğŸ’¡ ê³„ì‚° ê°€ì´ë“œ:\n"
        if has_reference and has_depth_scale and depth_scale_info.get('pixel_per_cm2_ratio'):
            prompt += "1. 'í”½ì…€ ë©´ì 'ì„ 'ë©´ì  ë¹„ìœ¨'ë¡œ ë‚˜ëˆ„ì–´ ìŒì‹ì˜ ì‹¤ì œ ë©´ì (cmÂ²)ì„ ê³„ì‚°í•˜ì„¸ìš”.\n"
            prompt += "2. 'ê¹Šì´ ë³€í™”ëŸ‰'ê³¼ 'ê¹Šì´ ìŠ¤ì¼€ì¼'ì„ ê³±í•˜ì—¬ ìŒì‹ì˜ ì‹¤ì œ ë†’ì´(cm)ë¥¼ ì¶”ì •í•˜ì„¸ìš”.\n"
            prompt += "3. ì¶”ì •ëœ ì‹¤ì œ ë©´ì ê³¼ ë†’ì´ë¥¼ ê³±í•´ ë¶€í”¼(cmÂ³)ë¥¼ ê³„ì‚°í•˜ì„¸ìš”. (í˜•íƒœ ë³´ì • ê³„ìˆ˜ 0.6 ì ìš©)\n"
            prompt += "4. ê³„ì‚°ëœ ë¶€í”¼ì— ìŒì‹ì˜ ì˜ˆìƒ ë°€ë„(g/cmÂ³)ë¥¼ ê³±í•´ ìµœì¢… ì§ˆëŸ‰(g)ì„ ê³„ì‚°í•˜ì„¸ìš”.\n"
        else:
            prompt += "ì •í™•í•œ ìŠ¤ì¼€ì¼ ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ, ìŒì‹ì˜ í”½ì…€ ë©´ì ê³¼ ì¼ë°˜ì ì¸ ìŒì‹ í¬ê¸°ë¥¼ ê³ ë ¤í•˜ì—¬ ê²½í—˜ì ìœ¼ë¡œ ì¶”ì •í•˜ì„¸ìš”. ì‹ ë¢°ë„ë¥¼ ë‚®ê²Œ ì„¤ì •í•˜ì„¸ìš”.\n"
        
        prompt += '\nğŸ“‹ ì‘ë‹µ í˜•ì‹ (JSON):\n{"estimated_mass_g": <ì¶”ì • ì§ˆëŸ‰(g)>, "confidence": <ì‹ ë¢°ë„(0.0~1.0)>, "reasoning": "<ê³„ì‚° ê³¼ì • ë° ê·¼ê±° ìš”ì•½>"}'
        return prompt.strip()

    def _build_prompt(self, features: dict) -> str:
        food_objects = features.get("food_objects", [])
        if not food_objects:
            return 'ìŒì‹ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. {"mass": 0, "confidence": 0.1, "reasoning": "ìŒì‹ ê°ì§€ ì‹¤íŒ¨"}'
        food = food_objects[0]
        reference_objects = features.get("reference_objects", [])
        depth_scale_info = features.get("depth_scale_info", {})
        has_reference = len(reference_objects) > 0
        has_depth_scale = depth_scale_info.get('has_scale', False)
        
        prompt = "ìŒì‹ ì§ˆëŸ‰ ì¶”ì • ë¶„ì„:\n\n"
        prompt += f"ğŸ½ï¸ ìŒì‹ ì •ë³´:\n  - ì¢…ë¥˜: {food.get('class_name', 'ì•Œìˆ˜ì—†ìŒ')}\n  - í”½ì…€ ë©´ì : {food.get('pixel_area', 0):,}í”½ì…€\n"
        food_depth = food.get('depth_info', {})
        prompt += f"  - í‰ê·  ê¹Šì´ê°’(ìƒëŒ€ì ): {food_depth.get('mean_depth', 0.0):.3f}\n  - ê¹Šì´ ë³€í™”ëŸ‰(ìƒëŒ€ì ): {food_depth.get('depth_variation', 0.0):.3f}\n"
        
        if has_reference:
            ref_obj = reference_objects[0]
            prompt += f"\nğŸ“ ê¸°ì¤€ ë¬¼ì²´ ì •ë³´:\n  - ì¢…ë¥˜: {ref_obj.get('class_name')}\n"
            real_size = ref_obj.get('real_size', {})
            if real_size:
                prompt += f"  - ì‹¤ì œ í¬ê¸°: {real_size.get('width', 0):.1f}cm Ã— {real_size.get('height', 0):.1f}cm, ë‘ê»˜: {real_size.get('thickness', 0):.1f}cm\n"
        
        if has_depth_scale:
            prompt += f"\nğŸ” ê³„ì‚°ëœ ì‹¤ì œ ìŠ¤ì¼€ì¼:\n  - ê¹Šì´ ìŠ¤ì¼€ì¼: {depth_scale_info.get('depth_scale_cm_per_unit', 0.0):.4f} cm/unit\n"
            if depth_scale_info.get('pixel_per_cm2_ratio'):
                prompt += f"  - ë©´ì  ë¹„ìœ¨: {depth_scale_info.get('pixel_per_cm2_ratio'):.2f} pixels/cmÂ²\n"
        
        prompt += "\nğŸ¯ ê³„ì‚° ê³¼ì œ:\nìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìŒì‹ì˜ ì§ˆëŸ‰ì„ g(ê·¸ë¨) ë‹¨ìœ„ë¡œ ì¶”ì •í•˜ì„¸ìš”. ë¶€í”¼(cmÂ³)ë¥¼ ë¨¼ì € ê³„ì‚°í•œ í›„, ì¼ë°˜ì ì¸ ìŒì‹ ë°€ë„(ì•½ 0.8~1.2 g/cmÂ³)ë¥¼ ì ìš©í•˜ì„¸ìš”.\n"
        prompt += "\nğŸ’¡ ê³„ì‚° ê°€ì´ë“œ:\n"
        if has_reference and has_depth_scale and depth_scale_info.get('pixel_per_cm2_ratio'):
            prompt += "1. 'í”½ì…€ ë©´ì 'ì„ 'ë©´ì  ë¹„ìœ¨'ë¡œ ë‚˜ëˆ„ì–´ ìŒì‹ì˜ ì‹¤ì œ ë©´ì (cmÂ²)ì„ ê³„ì‚°í•˜ì„¸ìš”.\n"
            prompt += "2. 'ê¹Šì´ ë³€í™”ëŸ‰'ê³¼ 'ê¹Šì´ ìŠ¤ì¼€ì¼'ì„ ê³±í•˜ì—¬ ìŒì‹ì˜ ì‹¤ì œ ë†’ì´(cm)ë¥¼ ì¶”ì •í•˜ì„¸ìš”.\n"
            prompt += "3. ì¶”ì •ëœ ì‹¤ì œ ë©´ì ê³¼ ë†’ì´ë¥¼ ê³±í•´ ë¶€í”¼(cmÂ³)ë¥¼ ê³„ì‚°í•˜ì„¸ìš”. (í˜•íƒœ ë³´ì • ê³„ìˆ˜ 0.6 ì ìš©)\n"
            prompt += "4. ê³„ì‚°ëœ ë¶€í”¼ì— ìŒì‹ì˜ ì˜ˆìƒ ë°€ë„(g/cmÂ³)ë¥¼ ê³±í•´ ìµœì¢… ì§ˆëŸ‰(g)ì„ ê³„ì‚°í•˜ì„¸ìš”.\n"
        else:
            prompt += "ì •í™•í•œ ìŠ¤ì¼€ì¼ ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ, ìŒì‹ì˜ í”½ì…€ ë©´ì ê³¼ ì¼ë°˜ì ì¸ ìŒì‹ í¬ê¸°ë¥¼ ê³ ë ¤í•˜ì—¬ ê²½í—˜ì ìœ¼ë¡œ ì¶”ì •í•˜ì„¸ìš”. ì‹ ë¢°ë„ë¥¼ ë‚®ê²Œ ì„¤ì •í•˜ì„¸ìš”.\n"
        prompt += '\nğŸ“‹ ì‘ë‹µ í˜•ì‹ (JSON):\n{"estimated_mass_g": <ì¶”ì • ì§ˆëŸ‰(g)>, "confidence": <ì‹ ë¢°ë„(0.0~1.0)>, "reasoning": "<ê³„ì‚° ê³¼ì • ë° ê·¼ê±° ìš”ì•½>"}'
        return prompt.strip()

    def _parse_response(self, response_text: str) -> dict:
        try:
            json_part = response_text.split('```json')[-1].split('```')[0].strip()
            return json.loads(json_part)
        except Exception as e:
            logging.error(f"LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}\nì›ë³¸ ì‘ë‹µ: {response_text}")
            return {"error": "LLM ì‘ë‹µì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

    def _build_multimodal_prompt(self, initial_estimation: dict, features: dict) -> str:
        food_objects = features.get("food_objects", [])
        food_count = len(food_objects)
        
        prompt = f"""
ìŒì‹ ì§ˆëŸ‰ ì¶”ì • ë©€í‹°ëª¨ë‹¬ ê²€ì¦:

ğŸ“Š ì´ˆê¸° ì¶”ì • ì •ë³´:
- ê°ì§€ëœ ìŒì‹ ê°œìˆ˜: {food_count}ê°œ
"""
        
        if "food_estimations" in initial_estimation:
            for i, est in enumerate(initial_estimation["food_estimations"]):
                if "error" not in est:
                    prompt += f"- ìŒì‹ {i+1} ì´ˆê¸° ì¶”ì • ì§ˆëŸ‰: {est.get('estimated_mass_g', 0):.1f}g\n"

        prompt += f"""
ğŸ” ê²€ì¦ ê³¼ì œ:
ì´ë¯¸ì§€ë¥¼ ë³´ê³  ë‹¤ìŒ ê·œì¹™ì— ë”°ë¼ ë‹¨ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”.

1.  **1ì°¨ ì‹œê°ì  ì‹ë³„**:
    - ì´ë¯¸ì§€ì— ë³´ì´ëŠ” ëª¨ë“  ìŒì‹ ë¬¼ì²´ë¥¼ ìˆëŠ” ê·¸ëŒ€ë¡œ ì„¤ëª…í•˜ì„¸ìš”
    - ìŒì‹ì´ ì—¬ëŸ¬ ê°œ ìˆë‹¤ë©´ ê°ê°ì„ êµ¬ë¶„í•˜ì—¬ ì„¤ëª…í•˜ì„¸ìš”

2.  **ì¬ê²€í†  ë° ìµœì¢… íŒë‹¨**:
    - 1ì°¨ ì‹ë³„ ê²°ê³¼ì— ëŒ€í•´ ë‹¤ë¥¸ ê°€ëŠ¥ì„±ì€ ì—†ëŠ”ì§€ ë¹„íŒì ìœ¼ë¡œ ê²€í† í•˜ì„¸ìš”.
    - **ì˜¤ë¥˜ ê°€ëŠ¥ì„± ì²´í¬**:
        - **ì¡°ëª…/ë°˜ì‚¬**: ì¡°ëª…ì´ë‚˜ í¬ì¥ì§€ ë°˜ì‚¬ ë•Œë¬¸ì— ìƒ‰ìƒì´ ì™œê³¡ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì˜ˆ: ê°ˆìƒ‰ì´ ë…¸ë—ê±°ë‚˜ ê²€ê²Œ ë³´ì¼ ìˆ˜ ìˆìŒ)
        - **ëª¨ì–‘ì˜ í•¨ì •**: íŠ¹ì • ëª¨ì–‘ì´ ì—¬ëŸ¬ ìŒì‹ì—ì„œ ë‚˜íƒ€ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì˜ˆ: ê½ƒ ëª¨ì–‘ì€ ê³¼ì, ë–¡, ì ¤ë¦¬ ë“± ë‹¤ì–‘í•¨)
    - ìœ„ ê°€ëŠ¥ì„±ì„ ê³ ë ¤í•˜ì—¬, 1ì°¨ íŒë‹¨ì´ ê°€ì¥ í•©ë¦¬ì ì¸ì§€, ì•„ë‹ˆë©´ ë” ì ì ˆí•œ ë‹¤ë¥¸ ìŒì‹ ì´ë¦„ì´ ìˆëŠ”ì§€ ìµœì¢… ê²°ë¡ ì„ ë‚´ë¦¬ì„¸ìš”.

3.  **ë¼ë²¨ í…ìŠ¤íŠ¸ ë¶„ì„**:
    - ë¼ë²¨ì´ ë³´ì´ë©´, ì œí’ˆëª…ê³¼ ì¤‘ëŸ‰(g ë˜ëŠ” ml)ì„ **ë³´ì´ëŠ” ê·¸ëŒ€ë¡œ ì¸ìš©**í•˜ì„¸ìš”.

ğŸ“‹ ì‘ë‹µ í˜•ì‹ (JSON):
{{
    "foods": [
        {{
            "food_name": "<ìŒì‹ ì´ë¦„>",
            "quoted_text": {{
                "product_name": "<ë¼ë²¨ì—ì„œ ì½ì€ ì œí’ˆëª… ê·¸ëŒ€ë¡œ>",
                "weight": "<ë¼ë²¨ì—ì„œ ì½ì€ ì¤‘ëŸ‰ ê·¸ëŒ€ë¡œ>"
            }},
            "verified_mass_g": <ì´ ìŒì‹ 1ê°œì˜ ì§ˆëŸ‰(g)>,
            "confidence": <ì‹ ë¢°ë„(0.0~1.0)>,
            "reasoning": "<ì´ ìŒì‹ì— ëŒ€í•œ ë¶„ì„ ê³¼ì • ë° ê·¼ê±°>"
        }}
    ],
    "overall_confidence": <ì „ì²´ ì‹ ë¢°ë„(0.0~1.0)>,
    "reasoning": "<ì „ì²´ ë¶„ì„ ê³¼ì • ë° ê·¼ê±°>"
}}
"""
        return prompt.strip()

    def _parse_multimodal_response(self, response_text: str, initial_estimation: dict) -> dict:
        try:
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                parsed = json.loads(json_match.group())
                return self._process_parsed_multimodal_response(parsed, initial_estimation)
            else:
                raise ValueError("JSON ì‘ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            logging.error(f"ë©€í‹°ëª¨ë‹¬ ì‘ë‹µ íŒŒì‹± ë° ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return {"error": f"ë©€í‹°ëª¨ë‹¬ ê²€ì¦ ì‹¤íŒ¨: {e}", "confidence": 0.1, "estimated_mass_g": initial_estimation.get('estimated_mass_g', 0)}

    def _process_parsed_multimodal_response(self, parsed: dict, initial_estimation: dict) -> dict:
        foods = parsed.get('foods', [])
        food_verifications = []
        
        for i, food_info in enumerate(foods):
            food_name = food_info.get('food_name', 'ì•Œìˆ˜ì—†ìŒ')
            reasoning = food_info.get('reasoning', 'ì¶”ë¡  ê³¼ì • ì—†ìŒ')
            confidence = food_info.get('confidence', 0.5)
            
            quoted_text = food_info.get('quoted_text', {})
            quoted_weight_str = quoted_text.get('weight')

            final_mass = None
            verification_method = "visual_estimation"

            # 1. ë¼ë²¨ì—ì„œ ì½ì€ ë¬´ê²Œ ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸
            if quoted_weight_str:
                mass_match = re.search(r'(\d+(?:\.\d+)?)', quoted_weight_str)
                if mass_match:
                    final_mass = float(mass_match.group(1))
                    confidence = 0.95
                    verification_method = "label_based"
                    logging.info(f"ë¼ë²¨ ì •ë³´ ê¸°ë°˜ ì§ˆëŸ‰ ì¶”ì •: {final_mass}g")

            # 2. ë¼ë²¨ ì •ë³´ê°€ ì—†ìœ¼ë©´, LLMì˜ ì‹œê°ì  íŒë‹¨ì— ì˜ì¡´
            if final_mass is None:
                final_mass = food_info.get('verified_mass_g', 0)
                logging.info(f"ì‹œê°ì  ì¶”ì • ê¸°ë°˜ ì§ˆëŸ‰: {final_mass}g")
            
            food_verifications.append({
                "food_index": i,
                "food_name": food_name,
                "verified_mass_g": final_mass,
                "confidence": confidence,
                "verification_method": verification_method,
                "quoted_text": quoted_text,
                "reasoning": reasoning
            })
            
        return {
            "food_verifications": food_verifications,
            "overall_confidence": parsed.get('overall_confidence', 0.5),
            "multimodal_estimation": parsed,
            "reasoning": parsed.get('reasoning', 'ì „ì²´ ë¶„ì„ ê³¼ì • ì—†ìŒ')
        }

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
llm_estimator = LLMMassEstimator()